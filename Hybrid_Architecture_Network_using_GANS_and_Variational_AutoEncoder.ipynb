{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hybrid_Architecture_Network.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/temiafeye/Colab-Projects/blob/master/Hybrid_Architecture_Network_using_GANS_and_Variational_AutoEncoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "725tZXJpflAJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "`# We are building an Hybrid Architecture Network, a combination of deep learning models, VAE+CPPN+GAN, to generate artistic images. \n",
        "The Hybrid Network consists of \n",
        "\n",
        "- VAE(variational autoencoder) = Q(encoder) + G(decoder)\n",
        "- GAN (generative adversarial network) = G(generator) + D(discriminator)\n",
        "- VAE - GAN = Q(encoder) + G(decoder/generator) + D(discriminator)\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "FaJcgt-9hFGe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Install Tensorflow 2.0 alpha\n",
        "!pip install -q tensorflow-gpu==2.0.0-alpha0\n",
        "# !pip install - q tensorboardcolab"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EoEuwFYgiIpf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.backend as K\n",
        "import tensorflow.keras.layers as layers\n",
        "import matplotlib.pyplot as plt\n",
        "import IPython.display as display\n",
        "import google.colab.files as files\n",
        "import sys, time\n",
        "import imageio, glob\n",
        "print('Python version: ', sys.version) \n",
        "print('Tensorflow version: ', tf.__version__)\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name !='/device:GPU:0':\n",
        "  raise SystemError('GPU Device not found')\n",
        "print('GPU found at: {}'. format(device_name))\n",
        "\n",
        "import tensorboardcolab as tbc\n",
        "tb = tbc.TensorBoardColab()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XXXpU0ENmo4u",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Define Global Variables\n"
      ]
    },
    {
      "metadata": {
        "id": "hvaa8N1zmwkp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "NBATCH = 500 #size of the mini-batch\n",
        "NX = 28 # image width \n",
        "NY = 28 #image height\n",
        "NC = 1 #number of channels ()\n",
        "NZ = 32 #VAE: size of latent variable\n",
        "SCALE = 6 #CPPN: zooming scale "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MAi9XKHFnwDr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#load the MNIST Dataset \n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KuLMsegmob_a",
        "colab_type": "code",
        "outputId": "9c0d9874-5391-43cc-a630-48cfae98c78d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "x_train = x_train.reshape(-1, NY, NX, NC).astype(np.float32) / 255.0\n",
        "x_test = x_test.reshape(-1, NY, NX, NC).astype(np.float32) / 255.0\n",
        "NSAMPLE = x_train.shape[0]\n",
        "x_batches = tf.data.Dataset.from_tensor_slices(x_train).shuffle(NSAMPLE).batch(NBATCH)\n",
        "print(x_train.shape, x_test.shape)\n",
        "\n",
        "def find_x(digit):\n",
        "  ''' find testing data by digit'''\n",
        "  i = -1\n",
        "  while i == -1 or y_test[i] != digit:\n",
        "    i = np.random.randit(y_test.shape[0])\n",
        "    return x_test[i:i+1]\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28, 1) (10000, 28, 28, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UJjHkW_MqY1a",
        "colab_type": "code",
        "outputId": "c4f445ae-1439-4c10-87aa-571b26225fca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "cell_type": "code",
      "source": [
        "''' Pre-calculate CPPN coordinate matrices'''\n",
        "def create_coordinates(nx=NX, ny=NY, scale=SCALE, nbatch=NBATCH):\n",
        "  n = (nx+ny) / 2\n",
        "  nx2, ny2 = nx/n*scale, ny/n*scale\n",
        "  xs, ys = np.meshgrid(np.linspace(-nx2, nx2, nx), np.linspace(-ny2, ny2, ny))\n",
        "  rs = np.sqrt(xs**2 + ys**2)\n",
        "  \n",
        "  xs_repeat = np.tile(np.reshape(xs, (1, nx*ny, 1)), (nbatch, 1, 1))\n",
        "  ys_repeat = np.tile(np.reshape(xs, (1, nx*ny, 1)), (nbatch, 1, 1))\n",
        "  rs_repeat = np.tile(np.reshape(xs, (1, nx*ny, 1)), (nbatch, 1, 1))\n",
        "  coords = np.concatenate((xs_repeat, ys_repeat, rs_repeat), axis=-1).astype(np.float32)\n",
        "  return coords, xs, ys, rs\n",
        "\n",
        "coords, xs, ys, rs = create_coordinates()\n",
        "plt.imshow(rs, cmap='jet')\n",
        "plt.colorbar()\n",
        "\n",
        "coords_sample, _, _, _ = create_coordinates(nbatch=5)\n",
        "\n",
        "print(coords.shape)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(500, 784, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAASQAAAD8CAYAAADe49kaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "FFqobP3Sva10",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Components - Define various compents of the hybrid structure"
      ]
    },
    {
      "metadata": {
        "id": "GalCezlgvgq4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "'''VAE (variational autoencoder) using MLP (multilayer perceptron)'''\n",
        "\n",
        "def model_vae_encoder(name='VAE-Q', nodes=32):\n",
        "  return tf.keras.Sequential([\n",
        "      layers.InputLayer(input_shape=(NY, NX, NC)),\n",
        "      layers.Flatten(),\n",
        "      layers.Dense(nodes, activation='relu'),\n",
        "      layers.Dense(nodes, activation='relu'),\n",
        "      layers.Dense(NZ + NZ),\n",
        "  ], name=name)\n",
        "\n",
        "def model_vae_decoder(name='VAE-P', nodes=32):\n",
        "  return tf.keras.Sequential([\n",
        "      layers.InputLayer(input_shape=(NZ,)),\n",
        "      layers.Dense(nodes, activation = 'relu'),\n",
        "      layers.Dense(nodes, activation = 'relu'),\n",
        "      layers.Dense(NX*NY*NC, activation = 'sigmoid'),\n",
        "      layers.Reshape([NY, NX, NC])\n",
        "  ], name=name)\n",
        "\n",
        "''' DCIGN (deep convolutional inverse graphics network)\n",
        "= VAE using CNN (convolutional neural network)'''\n",
        "\n",
        "def model_dcign_encoder(name='DCIGN-Q', nodes=32):\n",
        "  return tf.keras.Sequential([\n",
        "      layers.InputLayer(input_shape=(NY, NX, NC)),\n",
        "      layers.Conv2D(nodes*1, (3,3), strides=(2,2), padding='same', activation='relu'),\n",
        "      layers.Conv2D(nodes*2, (3,3), strides=(2,2), padding='same', activation='relu'),\n",
        "      layers.Flatten(),\n",
        "      layers.Dense(NZ+NZ),\n",
        "  ], name=name)\n",
        "\n",
        "def model_dcign_decoder(name='DCIGN-P', nodes=32):\n",
        "  return tf.keras.Sequential([\n",
        "      layers.InputLayer(input_shape=(NZ,)),\n",
        "      layers.Dense(7*7*nodes, activation='relu'),\n",
        "      layers.Reshape((7, 7, nodes)),\n",
        "      layers.Conv2DTranspose(nodes*2, (3,3), strides=(2,2), padding='same', activation='relu'),\n",
        "      layers.Conv2DTranspose(nodes*1, (3,3), strides=(2,2), padding='same', activation='relu'),\n",
        "      layers.Conv2DTranspose(NC, (3,3), strides=(1,1), padding='same', activation='relu'),\n",
        "  ], name=name)\n",
        "\n",
        "def param_splits(z_params):\n",
        "  return tf.split(z_params, 2, axis=1)\n",
        "\n",
        "def sample_func(z_params, mean=0, stddev=1):\n",
        "  z_mean, z_logvar = param_split(z_params)\n",
        "  eps = tf.random.normal(shape =tf.shape(z_mean), mean=mean, stddev=stddev)\n",
        "  return z_mean + tf.exp(z_lagvar * 0.5) * eps\n",
        "\n",
        "def sample(z_params, mean=0, stddev=1):\n",
        "  return layers.Lambda(sample_func)(z_params)\n",
        "\n",
        "''' CPPN(compositional pattern producing network)'''\n",
        "\n",
        "def repeat_vector(inputs):\n",
        "  vec_in, dim_in = inputs\n",
        "  return layers.RepeatVector(K.shape(dim_in)[1]) (vec_in)\n",
        "\n",
        "def model_cppn_generator(name='CPPN_G', levels=4, nodes=32, stddev=1):\n",
        "  normal_init = tf.keras.initializers.RandomNormal (stddev = stddev)\n",
        "  inits = {'kernel_initializer': normal_init} #this initializes the biases\n",
        "  \n",
        "  z_in = layers.Input(shape=(NZ,))\n",
        "  coord_in = layers.Input(shape=(None, 3))\n",
        "  h = layers.Lambda(repeat_vector, ouptut_shape=(None, NZ))([z_in, coord_in])\n",
        "  h = layers.Concatenate() ([h, coord_in])\n",
        "  h = layers.Dense(nodes, activation='softplus', **inits) (h)\n",
        "  for i in range(levels):\n",
        "    h = layers.Dense(nodes, activation='tanh', **inits) (h)\n",
        "  h = layers.Dense(NC, activation='sigmoid', **inits) (h)\n",
        "  x_out = layers.Flatten() (h)\n",
        "  return tf.keras.Model(inputs=[z_in, coord_in], ouputs = x_out, name=name)\n",
        "\n",
        "def sq(x, nx=NX, ny=NY, nc=NC):\n",
        "  return tf.reshape(x, (-1, ny, nx, nc))\n",
        "\n",
        "\n",
        "''' DCGAN(deep convolutional generative adversarial network) '''\n",
        "def model_dcgan_generator(name='DCGAN-G', filters=32, stddev=0.02):\n",
        "  inits = {}\n",
        "  model = tf.keras.Sequential(name=name)\n",
        "  model.add(layers.InputLayer(input_shape=(NZ,)))\n",
        "  model.add(layers.Dense(7*7*filters*4, **inits))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.ReLU())\n",
        "  model.add(layers.Reshape((7,7, filters*4)))\n",
        "  for f, s in zip([2,1], [1,2]):\n",
        "    model.add(layers.Conv2DTranspose(filters*f, (5,5), strides=(s,s), padding='same', **inits))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.ReLU)\n",
        "  model.add(layers.Conv2DTranspose(NC, (5,5), strides=(2,2), padding='same', **inits, activation='tanh'))\n",
        "  assert model.output_shape == (None, NY, NX,NC)\n",
        "  return model\n",
        "\n",
        "def model_dcgan_discriminator(name='DCGAN-D', filters=32, stddev=0.02):\n",
        "  inits = {}\n",
        "  \n",
        "  model = tf.keras.Sequential(name=name)\n",
        "  model.add(layers.InputLayer(input_shape=(NY, NX, NC)))\n",
        "  for f in [1,2]:\n",
        "    model.add(layers.Conv2D(filters*f, (5,5), strides=(2,2), padding='same', **inits))\n",
        "    if f>1: model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(1, **inits)) \n",
        "    return model \n",
        "  \n",
        "''' show graph of models'''\n",
        "\n",
        "def display_models(models):\n",
        "  imgs = []\n",
        "  for m in models:\n",
        "    tf.keras.utils.plot_models(m, to_file=m.name+'.png', show_shapes=True, show_layer=True)\n",
        "    imgs.append(m.name)\n",
        "    imgs.append(display.Image(retina=True, filename=m.name+'.png'))\n",
        "    display.display(*imgs)\n",
        "  \n",
        "\n",
        "\n",
        "\n",
        "              \n",
        "\n",
        "\n",
        "                    \n",
        "                   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CKe0wpF4syFb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "''' Define Loss function '''\n",
        "def kid(z_mean, z_logvar):\n",
        "  ''' Kullback-LEibler divergence in VAE'''\n",
        "  return -0.5 * K.sum(1 + z_logvar - K.square(z_mean) - K.exp(z_logvar), axis=1) / (NX*NY*NC)\n",
        "\n",
        "def bce(y1, y2):\n",
        "  ''' Binary cross entropy for use in AE'''\n",
        "  y1_flat = tf.reshape(y1, (-1, NX*NY*NC))\n",
        "  y2_flat = tf.reshape(y1, (-1, NX*NY*NC))\n",
        "  return tf.keras.losses.binary_crossentropy(y1_flat, y2_flat)\n",
        "\n",
        "def bce_logits(b,y):\n",
        "  ''' Binary cross-entropy from logits for use in GAN'''\n",
        "  truth = tf.ones_like(y) if b else tf.zeros_like(y)\n",
        "  return tf.keras.losses.binary_crossentropy(truth, y, from_logits=True)\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "d_FWVq7ivj3O",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Test"
      ]
    },
    {
      "metadata": {
        "id": "6ADSUFImvhyi",
        "colab_type": "code",
        "outputId": "8aae95b9-fac1-4887-9f73-0fbd39cd7f9f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        }
      },
      "cell_type": "code",
      "source": [
        "len(all_g_loss) /NSAMPLE*NBATCH"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-1133f0950297>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_g_loss\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m\u001b[0mNSAMPLE\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mNBATCH\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'all_g_loss' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "-0iHrJGyvwB8",
        "colab_type": "code",
        "outputId": "fbf2f57e-3b91-4972-8d20-e5ab26ff852f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 708
        }
      },
      "cell_type": "code",
      "source": [
        "''' test CPPN '''\n",
        "g = model_cppn_generator(levels=4, nodes=64, stddev=1)\n",
        "\n",
        "XL = 20\n",
        "coords_test = create_coordinates(nx=NX*XL, ny=NY*XL, scale=6, nbatch=1)\n",
        "\n",
        "noise_z = tf.random.normal((1, NZ), stddev=1)\n",
        "x3 = sq(g([noise_z, coords_test]), nx=NX*XL, ny=NY*XL)\n",
        "\n",
        "plt.figure(figsize=(8,12))\n",
        "plt.imshow(tf.reshape(x3[0], (NY*XL, NX*XL)), vmin=0, vmax=1, cmap='gray')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-f4259acbc99d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m''' test CPPN '''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_cppn_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlevels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnodes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstddev\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mXL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcoords_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_coordinates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNX\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mXL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mny\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNY\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mXL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-36-32ae28ee8afe>\u001b[0m in \u001b[0;36mmodel_cppn_generator\u001b[0;34m(name, levels, nodes, stddev)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0mz_in\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNZ\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m   \u001b[0mcoord_in\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m   \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLambda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepeat_vector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouptut_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNZ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mz_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoord_in\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m   \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoord_in\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m   \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'softplus'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0minits\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/core.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, function, output_shape, mask, arguments, **kwargs)\u001b[0m\n\u001b[1;32m    670\u001b[0m   def __init__(self, function, output_shape=None, mask=None, arguments=None,\n\u001b[1;32m    671\u001b[0m                **kwargs):\n\u001b[0;32m--> 672\u001b[0;31m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLambda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    673\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marguments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marguments\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0marguments\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/checkpointable/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    440\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 442\u001b[0;31m       \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    443\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, trainable, name, dtype, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkwarg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mkwarg\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mallowed_kwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Keyword argument not understood:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwarg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;31m# Mutable properties\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: ('Keyword argument not understood:', 'ouptut_shape')"
          ]
        }
      ]
    }
  ]
}